{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1: \"Usando una GPU\" (opcional)\n",
    "\n",
    "Ejecutar el codigo anterior en una GPU. Utilizando T4 en google collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(1000,1000)\n",
    "B = torch.rand(1000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 ms ± 423 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A@B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    A = A.cuda()\n",
    "    B = B.cuda()\n",
    "    print(\"CUDA available\")\n",
    "else:\n",
    "    print(\"CUDA not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.2 ms ± 1.04 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A@B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observer la velicidad con GPU es mucho mas rapida que sin GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2: \"Calculo del gradiente\" (opcional)\n",
    "\n",
    "Dada las siguientes definiciones:\n",
    "\n",
    "$a = 2$\n",
    "\n",
    "$b = 3$\n",
    "\n",
    "$c = -1$\n",
    "\n",
    "$d = 7$\n",
    "\n",
    "$m = 3 \\times a + 4 \\times b - 2 \\times c + 10 \\times d$\n",
    "\n",
    "$n = 7 \\times a + b + \\times c + 4 \\times d$\n",
    "\n",
    "$p = max(m,0)$\n",
    "\n",
    "$q = max(n,0)$\n",
    "\n",
    "$z = p - q$\n",
    "\n",
    "$ pred = \\frac{1}{1 + e^{-x}}$\n",
    "\n",
    "$loss = log(pred)$\n",
    "\n",
    "Calcular:\n",
    "\n",
    "1. El grafo de las computaciones (un diagrama de flechas como el de arriba donde se vea la relación de dependencia entre las variables).\n",
    "2. Las derivadas $\\large \\frac{\\partial loss}{\\partial a}$, $\\large \\frac{\\partial loss}{\\partial b}$, $\\large \\frac{\\partial loss}{\\partial c}$, $\\large \\frac{\\partial loss}{\\partial d}$ manualmente.\n",
    "3. Las derivadas $\\large \\frac{\\partial loss}{\\partial a}$, $\\large \\frac{\\partial loss}{\\partial b}$, $\\large \\frac{\\partial loss}{\\partial c}$, $\\large \\frac{\\partial loss}{\\partial d}$ utilizando Pytorch Autograd (backwards).\n",
    "4. Una aproximación de las derivadas $\\large \\frac{\\partial loss}{\\partial a}$, $\\large \\frac{\\partial loss}{\\partial b}$, $\\large \\frac{\\partial loss}{\\partial c}$, $\\large \\frac{\\partial loss}{\\partial d}$ mediante los ratios $\\large \\frac{\\Delta loss}{\\Delta a}$, $\\large \\frac{\\Delta loss}{\\Delta b}$, $\\large \\frac{\\Delta loss}{\\Delta c}$, $\\large \\frac{\\Delta loss}{\\Delta d}$ de cambio utilizando pequeñas variaciones $\\Delta a$, $\\Delta b$, $\\Delta c$, $\\Delta d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "# Definición de tensores\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "c = torch.tensor(-1.0, requires_grad=True)\n",
    "d = torch.tensor(7.0, requires_grad=True)\n",
    "\n",
    "m = 3 * a + 4 * - 2 * c + 10 * d\n",
    "n = 7 * a + b + c + 4 * d\n",
    "\n",
    "p = torch.max(m,0)\n",
    "q = torch.max(n,0)\n",
    "\n",
    "z = p[0] - q[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de las funciones con las correcciones\n",
    "def pred(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "def loss(x):\n",
    "    pred = 1 / (1 + torch.exp(-x))\n",
    "    return torch.log(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40., grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retener los gradientes antes de aplicar backpropagation\n",
    "for t in  [a, b, c, d, n, m, p[0], q[0], z ]:\n",
    "    t.retain_grad()\n",
    "\n",
    "# aplicar backpropagation\n",
    "z.backward()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7311, grad_fn=<MulBackward0>),\n",
       " tensor(-0.3133, grad_fn=<LogBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)  # Variable adicional x\n",
    "pred1 = pred(x)\n",
    "loss1 = loss(x)\n",
    "\n",
    "pred1, loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-4.), tensor(-1.), tensor(-9.), tensor(6.))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.\n",
    "a.grad, b.grad, c.grad, d.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Utilizando auto grad\n",
    "\n",
    "def calculate_l(a,b,c,d):\n",
    "    m = 3 * a + 4 * - 2 * c + 10 * d\n",
    "    n = 7 * a + b + c + 4 * d\n",
    "\n",
    "    p = torch.max(m,0)\n",
    "    q = torch.max(n,0)\n",
    "\n",
    "    return p[0] - q[0]\n",
    "\n",
    "ov = calculate_l(a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value: 39.99599838256836\n",
      "Change value: -0.004001617431640625\n",
      "Change ration: -4.001617431640625\n"
     ]
    }
   ],
   "source": [
    "# 4. Introducir pequeños cambios\n",
    "\n",
    "small_change = 0.001\n",
    "nv = calculate_l(a + small_change, b, c, d)\n",
    "print(f'New value: {(nv).item()}')\n",
    "print(f'Change value: {(nv - ov).item()}')\n",
    "print(f'Change ration: {((nv - ov) / small_change).item()}')\n",
    "\n",
    "# Se observa que el cambio en la variable a tiene un ratio de 4 tal cual calculamos el gradiente anteriormente de z en funcion de x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.1 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.3.1-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: torch==2.3.1 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torchaudio) (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchaudio) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchaudio) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchaudio) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchaudio) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchaudio) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchaudio) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchaudio) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchaudio) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchaudio) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch==2.3.1->torchaudio) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch==2.3.1->torchaudio) (1.3.0)\n",
      "Downloading torchaudio-2.3.1-cp311-cp311-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.4 MB 262.6 kB/s eta 0:00:09\n",
      "    --------------------------------------- 0.0/2.4 MB 262.6 kB/s eta 0:00:09\n",
      "    --------------------------------------- 0.0/2.4 MB 262.6 kB/s eta 0:00:09\n",
      "    --------------------------------------- 0.0/2.4 MB 262.6 kB/s eta 0:00:09\n",
      "    --------------------------------------- 0.0/2.4 MB 262.6 kB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.1/2.4 MB 358.2 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.2/2.4 MB 367.6 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.2/2.4 MB 367.6 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.2/2.4 MB 367.6 kB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.2/2.4 MB 375.1 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 414.4 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 421.5 kB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 437.1 kB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 437.1 kB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 437.1 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.4/2.4 MB 461.6 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.4/2.4 MB 471.7 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.5/2.4 MB 494.3 kB/s eta 0:00:04\n",
      "   -------- ------------------------------- 0.5/2.4 MB 530.7 kB/s eta 0:00:04\n",
      "   --------- ------------------------------ 0.6/2.4 MB 556.2 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 0.6/2.4 MB 568.9 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 0.6/2.4 MB 572.5 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 0.6/2.4 MB 572.5 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 0.7/2.4 MB 585.9 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.7/2.4 MB 580.9 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.8/2.4 MB 583.5 kB/s eta 0:00:03\n",
      "   ------------- -------------------------- 0.8/2.4 MB 594.7 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 0.9/2.4 MB 611.5 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 0.9/2.4 MB 619.7 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 0.9/2.4 MB 634.8 kB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 1.0/2.4 MB 628.7 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 649.0 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 636.5 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.1/2.4 MB 643.1 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.1/2.4 MB 643.4 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.1/2.4 MB 626.1 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 1.1/2.4 MB 632.9 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.2/2.4 MB 628.0 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.2/2.4 MB 628.1 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.2/2.4 MB 629.2 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.4 MB 634.8 kB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 1.3/2.4 MB 640.6 kB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 1.3/2.4 MB 650.6 kB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 1.4/2.4 MB 636.1 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.4/2.4 MB 636.8 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.4/2.4 MB 641.7 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.5/2.4 MB 650.8 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.5/2.4 MB 651.1 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.6/2.4 MB 659.8 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.6/2.4 MB 655.4 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.6/2.4 MB 659.7 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.7/2.4 MB 667.8 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.7/2.4 MB 671.8 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.7/2.4 MB 667.3 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 671.0 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 678.3 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.4 MB 678.1 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.9/2.4 MB 674.0 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.9/2.4 MB 673.9 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.9/2.4 MB 673.5 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.4 MB 683.9 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.4 MB 676.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.0/2.4 MB 682.9 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.1/2.4 MB 682.7 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.1/2.4 MB 682.7 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.1/2.4 MB 685.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.2/2.4 MB 684.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.2/2.4 MB 690.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.3/2.4 MB 690.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.3/2.4 MB 690.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.4 MB 692.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 691.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 688.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 683.1 kB/s eta 0:00:00\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.3.1\n",
      "Requirement already satisfied: tensorboard in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard) (1.64.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hgarnica\\appdata\\local\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# 1. Diagrama de grafo\n",
    "\n",
    "!pip install torchvision\n",
    "!pip install torchaudio\n",
    "!pip install tensorboard\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del grafo de dependenciasimport torch\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# Crear un escritor de TensorBoard\n",
    "writer = SummaryWriter('runs/grafo_de_dependencias')\n",
    "\n",
    "# Usar torch.jit.trace para trazar el grafo\n",
    "traced_model = torch.jit.trace(loss, (x,))\n",
    "#writer.add_graph(traced_model, x)\n",
    "\n",
    "# Cierra el escritor\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3: \"Resolviendo un sistema de ecuaciones utilizando descenso por gradiente\" (opcional)\n",
    "\n",
    "Utilizar el método de descenso por gradiente para resolver el siguiente sistema de ecuaciones:\n",
    "\n",
    "$ 3 x + 4 y - 2 z = 0$\n",
    "\n",
    "$ 2 x - 3 y + 4 z = 11$\n",
    "\n",
    "$ x - 2 y + 3 z = 7$\n",
    "\n",
    "Hint: recordar la representación matricial del sistema de ecuaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3.,   4.,  -2.,   0.],\n",
       "        [  2.,  -3.,   4., -11.],\n",
       "        [  1.,  -2.,   3.,  -7.],\n",
       "        [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Armamos la matriz del sistema de ecuaciones\n",
    "values = [[3,4,-2, 0],\n",
    "          [2,-3,4,-11],\n",
    "          [1,-2,3,-7],\n",
    "          [0,0,0,0]]\n",
    "A = torch.tensor(values, dtype=torch.float)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la función objetivo\n",
    "def f(W):\n",
    "    dim = A.shape[0]\n",
    "    I = torch.eye(dim)\n",
    "    return torch.norm(A @ W - I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1441, 0.2708, 0.9284, 0.1473],\n",
       "        [0.6843, 0.4514, 0.2903, 0.2161],\n",
       "        [0.6810, 0.7366, 0.0601, 0.1720],\n",
       "        [0.7562, 0.0343, 0.0887, 0.2896]], requires_grad=True)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializamos una matriz W aleatorio para iniciar\n",
    "\n",
    "W = torch.rand((4,4), requires_grad=True)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(W) = 10.377083778381348\n",
      "tensor([[0.1441, 0.2708, 0.9284, 0.1473],\n",
      "        [0.6843, 0.4514, 0.2903, 0.2161],\n",
      "        [0.6810, 0.7366, 0.0601, 0.1720],\n",
      "        [0.7562, 0.0343, 0.0887, 0.2896]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Defino la funciçon de iteracción\n",
    "\n",
    "def iteration_gradient_descent(learning_rate = 0.01, show_value=False):\n",
    "    value = f(W)\n",
    "    if show_value:\n",
    "        print(f'f(W) = {value.item()}')\n",
    "        print(W)\n",
    "    value.backward()\n",
    "    W.data = W.data - learning_rate * W.grad\n",
    "    W.grad.zero_()\n",
    "\n",
    "iteration_gradient_descent(show_value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(W) = 1.0725104808807373\n",
      "tensor([[ 0.3800,  0.5948, -0.0175,  0.1556],\n",
      "        [ 0.0828, -1.0744,  1.2305, -0.0798],\n",
      "        [ 0.2525, -1.2591,  2.4362,  0.0806],\n",
      "        [ 0.1113, -0.1437,  0.5448,  0.0686]], requires_grad=True)\n",
      "f(W) = 10.725147247314453\n",
      "tensor([[ 0.4648,  0.5825, -0.0102,  0.1894],\n",
      "        [-0.0920, -1.0492,  1.2155, -0.1494],\n",
      "        [ 0.4796, -1.2919,  2.4558,  0.1710],\n",
      "        [-0.4602, -0.0613,  0.4955, -0.1592]], requires_grad=True)\n",
      "f(W) = 10.725147247314453\n",
      "tensor([[ 0.4648,  0.5825, -0.0102,  0.1894],\n",
      "        [-0.0920, -1.0492,  1.2155, -0.1494],\n",
      "        [ 0.4796, -1.2919,  2.4558,  0.1710],\n",
      "        [-0.4602, -0.0613,  0.4955, -0.1592]], requires_grad=True)\n",
      "f(W) = 10.725147247314453\n",
      "tensor([[ 0.4648,  0.5825, -0.0102,  0.1894],\n",
      "        [-0.0920, -1.0492,  1.2155, -0.1494],\n",
      "        [ 0.4796, -1.2919,  2.4558,  0.1710],\n",
      "        [-0.4602, -0.0613,  0.4955, -0.1592]], requires_grad=True)\n",
      "f(W) = 1.0725104808807373\n",
      "tensor([[ 0.3736,  0.5957, -0.0181,  0.1530],\n",
      "        [ 0.0960, -1.0763,  1.2317, -0.0745],\n",
      "        [ 0.2354, -1.2567,  2.4348,  0.0737],\n",
      "        [ 0.1544, -0.1499,  0.5485,  0.0857]], requires_grad=True)\n",
      "f(W) = 1.0725104808807373\n",
      "tensor([[ 0.3736,  0.5957, -0.0181,  0.1530],\n",
      "        [ 0.0960, -1.0763,  1.2317, -0.0745],\n",
      "        [ 0.2354, -1.2567,  2.4348,  0.0737],\n",
      "        [ 0.1544, -0.1499,  0.5485,  0.0857]], requires_grad=True)\n",
      "f(W) = 1.0725104808807373\n",
      "tensor([[ 0.3736,  0.5957, -0.0181,  0.1530],\n",
      "        [ 0.0960, -1.0763,  1.2317, -0.0745],\n",
      "        [ 0.2354, -1.2567,  2.4348,  0.0737],\n",
      "        [ 0.1544, -0.1499,  0.5485,  0.0857]], requires_grad=True)\n",
      "f(W) = 1.0\n",
      "tensor([[ 0.3768,  0.5952, -0.0178,  0.1543],\n",
      "        [ 0.0894, -1.0754,  1.2311, -0.0771],\n",
      "        [ 0.2440, -1.2579,  2.4355,  0.0772],\n",
      "        [ 0.1329, -0.1468,  0.5466,  0.0771]], requires_grad=True)\n",
      "f(W) = 1.0\n",
      "tensor([[ 0.3768,  0.5952, -0.0178,  0.1543],\n",
      "        [ 0.0894, -1.0754,  1.2311, -0.0771],\n",
      "        [ 0.2440, -1.2579,  2.4355,  0.0772],\n",
      "        [ 0.1329, -0.1468,  0.5466,  0.0771]], requires_grad=True)\n",
      "f(W) = 1.0\n",
      "tensor([[ 0.3768,  0.5952, -0.0178,  0.1543],\n",
      "        [ 0.0894, -1.0754,  1.2311, -0.0771],\n",
      "        [ 0.2440, -1.2579,  2.4355,  0.0772],\n",
      "        [ 0.1329, -0.1468,  0.5466,  0.0771]], requires_grad=True)\n",
      "f(W) = 1.0\n",
      "tensor([[ 0.3768,  0.5952, -0.0178,  0.1543],\n",
      "        [ 0.0894, -1.0754,  1.2311, -0.0771],\n",
      "        [ 0.2440, -1.2579,  2.4355,  0.0772],\n",
      "        [ 0.1329, -0.1468,  0.5466,  0.0771]], requires_grad=True)\n",
      "f(W) = 1.0\n",
      "tensor([[ 0.3768,  0.5952, -0.0178,  0.1543],\n",
      "        [ 0.0894, -1.0754,  1.2311, -0.0771],\n",
      "        [ 0.2440, -1.2579,  2.4355,  0.0772],\n",
      "        [ 0.1329, -0.1468,  0.5466,  0.0771]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Realizo las iteracciones buscando minimizar la función objetivo\n",
    "\n",
    "for lr_exponent in range(1,5):\n",
    "    n_iter_to_show = 100000\n",
    "    n_iter = n_iter_to_show * 3\n",
    "    learning_rate = 0.1 ** lr_exponent\n",
    "    for iteration_number in range(n_iter):\n",
    "        iteration_gradient_descent(show_value = (iteration_number%n_iter_to_show == 0), learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3768,  0.5952, -0.0178,  0.1543],\n",
       "        [ 0.0894, -1.0754,  1.2311, -0.0771],\n",
       "        [ 0.2440, -1.2579,  2.4355,  0.0772],\n",
       "        [ 0.1329, -0.1468,  0.5466,  0.0771]], requires_grad=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valores minimos encontrados de la matriz W para esa cantidad de iteracciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "faltan iteraccion para poder llegar a 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
